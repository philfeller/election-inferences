---
title: "Uncertainly in Voter Transition Estimates"
output: html_document
---

```{r setup, include=FALSE}
wd <- getwd()
setwd("../")
source("./global.R", local = TRUE)
source("./present.R", local = TRUE)
load("./1852_covariate_inference.Rda")
load("./1853_covariate_inference.Rda")
load("./1854_covariate_inference.Rda")
load("./1855_covariate_inference.Rda")
load("./1856_covariate_inference.Rda")
load("./1857_covariate_inference.Rda")
setwd(dirname(wd))
```
There are three different ways to look at the amount of uncertainty in a model. One, illustrated in the leftmost heatmaps below, looks at the percentage of the variation in the model's estimates that is due to different runs beginning with a different random starting point. This is known as "between-run" variability. A second way, shown in the middle heatmaps below, looks at the percentage of pairwise run comparisons that have non-overlapping 95% credible intervals. The third way, shown in the rightmost heatmaps, looks at the coefficient of variation (CV) for each transition, which is the standard deviation of the estimates divided by the mean estimate.

```{r plots, echo=FALSE}
combined_uncertainty.52 <- create_combined_uncertainty_heatmap(variability_results.52, 1851, 1852)
plot(combined_uncertainty.52)
combined_uncertainty.53 <- create_combined_uncertainty_heatmap(variability_results.53, 1852, 1853)
plot(combined_uncertainty.53)
combined_uncertainty.54 <- create_combined_uncertainty_heatmap(variability_results.54, 1853, 1854)
plot(combined_uncertainty.54)
combined_uncertainty.55 <- create_combined_uncertainty_heatmap(variability_results.55, 1854, 1855)
plot(combined_uncertainty.55)
combined_uncertainty.56 <- create_combined_uncertainty_heatmap(variability_results.56, 1855, 1856)
plot(combined_uncertainty.56)
combined_uncertainty.57 <- create_combined_uncertainty_heatmap(variability_results.57, 1856, 1857)
plot(combined_uncertainty.57)
```